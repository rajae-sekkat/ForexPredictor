{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Download data for EUR/USD and USD/JPY\n",
    "eur_usd= yf.download('EURUSD=X', start='2012-01-01', end='2022-12-31')\n",
    "jpy_usd=yf.download('JPYUSD=X', start='2012-01-01', end='2022-12-31')\n",
    "\n",
    "# Save the Data as csv\n",
    "eur_usd.to_csv('eur_usd.csv')\n",
    "jpy_usd.to_csv('jpy_usd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the data\n",
    "eur_usd = pd.read_csv('eur_usd.csv', index_col='Date', parse_dates=True)\n",
    "jpy_usd = pd.read_csv('jpy_usd.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Combine the datasets\n",
    "data = pd.concat([eur_usd['Close'], jpy_usd['Close']], axis=1)\n",
    "data.columns = ['EURUSD', 'USDJPY']\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns, index=data.index)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(data_scaled) * 0.8)\n",
    "train_data = data_scaled[:train_size]\n",
    "test_data = data_scaled[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([32, 2])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([20, 2])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.02591935358941555\n",
      "Epoch 2/50, Loss: 0.02034868113696575\n",
      "Epoch 3/50, Loss: 0.011470948345959187\n",
      "Epoch 4/50, Loss: 0.006425137631595135\n",
      "Epoch 5/50, Loss: 0.01271386444568634\n",
      "Epoch 6/50, Loss: 0.01203925535082817\n",
      "Epoch 7/50, Loss: 0.010944143868982792\n",
      "Epoch 8/50, Loss: 0.017211580649018288\n",
      "Epoch 9/50, Loss: 0.01495576836168766\n",
      "Epoch 10/50, Loss: 0.009895658120512962\n",
      "Epoch 11/50, Loss: 0.006396540440618992\n",
      "Epoch 12/50, Loss: 0.011937248520553112\n",
      "Epoch 13/50, Loss: 0.01562761329114437\n",
      "Epoch 14/50, Loss: 0.007457879837602377\n",
      "Epoch 15/50, Loss: 0.007917645387351513\n",
      "Epoch 16/50, Loss: 0.0067226700484752655\n",
      "Epoch 17/50, Loss: 0.011585848405957222\n",
      "Epoch 18/50, Loss: 0.007037130184471607\n",
      "Epoch 19/50, Loss: 0.012033526785671711\n",
      "Epoch 20/50, Loss: 0.010453899390995502\n",
      "Epoch 21/50, Loss: 0.016190819442272186\n",
      "Epoch 22/50, Loss: 0.01156492531299591\n",
      "Epoch 23/50, Loss: 0.022240495309233665\n",
      "Epoch 24/50, Loss: 0.00286888494156301\n",
      "Epoch 25/50, Loss: 0.007952190935611725\n",
      "Epoch 26/50, Loss: 0.012158055789768696\n",
      "Epoch 27/50, Loss: 0.006427390035241842\n",
      "Epoch 28/50, Loss: 0.016748199239373207\n",
      "Epoch 29/50, Loss: 0.011162381619215012\n",
      "Epoch 30/50, Loss: 0.010577132925391197\n",
      "Epoch 31/50, Loss: 0.009847080335021019\n",
      "Epoch 32/50, Loss: 0.0071673281490802765\n",
      "Epoch 33/50, Loss: 0.01246045995503664\n",
      "Epoch 34/50, Loss: 0.005604610778391361\n",
      "Epoch 35/50, Loss: 0.00886338297277689\n",
      "Epoch 36/50, Loss: 0.008642195723950863\n",
      "Epoch 37/50, Loss: 0.003976934589445591\n",
      "Epoch 38/50, Loss: 0.017273200675845146\n",
      "Epoch 39/50, Loss: 0.010808908380568027\n",
      "Epoch 40/50, Loss: 0.009428945370018482\n",
      "Epoch 41/50, Loss: 0.007338223047554493\n",
      "Epoch 42/50, Loss: 0.01116411853581667\n",
      "Epoch 43/50, Loss: 0.008726273663341999\n",
      "Epoch 44/50, Loss: 0.01213024090975523\n",
      "Epoch 45/50, Loss: 0.012854352593421936\n",
      "Epoch 46/50, Loss: 0.010812708176672459\n",
      "Epoch 47/50, Loss: 0.010555174201726913\n",
      "Epoch 48/50, Loss: 0.015405217185616493\n",
      "Epoch 49/50, Loss: 0.0047965282574296\n",
      "Epoch 50/50, Loss: 0.008832859806716442\n",
      "Epoch 1/50, Loss: 0.021407466381788254\n",
      "Epoch 2/50, Loss: 0.01648620516061783\n",
      "Epoch 3/50, Loss: 0.011621782556176186\n",
      "Epoch 4/50, Loss: 0.009423547424376011\n",
      "Epoch 5/50, Loss: 0.009266292676329613\n",
      "Epoch 6/50, Loss: 0.006807729601860046\n",
      "Epoch 7/50, Loss: 0.014125784859061241\n",
      "Epoch 8/50, Loss: 0.012871498242020607\n",
      "Epoch 9/50, Loss: 0.013015538454055786\n",
      "Epoch 10/50, Loss: 0.013242991641163826\n",
      "Epoch 11/50, Loss: 0.011152433231472969\n",
      "Epoch 12/50, Loss: 0.012487737461924553\n",
      "Epoch 13/50, Loss: 0.006827699951827526\n",
      "Epoch 14/50, Loss: 0.009197008796036243\n",
      "Epoch 15/50, Loss: 0.01900474727153778\n",
      "Epoch 16/50, Loss: 0.008253263309597969\n",
      "Epoch 17/50, Loss: 0.014545217156410217\n",
      "Epoch 18/50, Loss: 0.010802226141095161\n",
      "Epoch 19/50, Loss: 0.01744256354868412\n",
      "Epoch 20/50, Loss: 0.005147147458046675\n",
      "Epoch 21/50, Loss: 0.009405186399817467\n",
      "Epoch 22/50, Loss: 0.015240211971104145\n",
      "Epoch 23/50, Loss: 0.011128420010209084\n",
      "Epoch 24/50, Loss: 0.01522099506109953\n",
      "Epoch 25/50, Loss: 0.015504817478358746\n",
      "Epoch 26/50, Loss: 0.013447520323097706\n",
      "Epoch 27/50, Loss: 0.011506388895213604\n",
      "Epoch 28/50, Loss: 0.010300042107701302\n",
      "Epoch 29/50, Loss: 0.010260721668601036\n",
      "Epoch 30/50, Loss: 0.0078448336571455\n",
      "Epoch 31/50, Loss: 0.015824049711227417\n",
      "Epoch 32/50, Loss: 0.006557483226060867\n",
      "Epoch 33/50, Loss: 0.010721253231167793\n",
      "Epoch 34/50, Loss: 0.00991358794271946\n",
      "Epoch 35/50, Loss: 0.008198615163564682\n",
      "Epoch 36/50, Loss: 0.01481637079268694\n",
      "Epoch 37/50, Loss: 0.007533407304435968\n",
      "Epoch 38/50, Loss: 0.010341688990592957\n",
      "Epoch 39/50, Loss: 0.010175122879445553\n",
      "Epoch 40/50, Loss: 0.015881437808275223\n",
      "Epoch 41/50, Loss: 0.004957010503858328\n",
      "Epoch 42/50, Loss: 0.006409765686839819\n",
      "Epoch 43/50, Loss: 0.007007876876741648\n",
      "Epoch 44/50, Loss: 0.005151563324034214\n",
      "Epoch 45/50, Loss: 0.012493111193180084\n",
      "Epoch 46/50, Loss: 0.00997119676321745\n",
      "Epoch 47/50, Loss: 0.011153357103466988\n",
      "Epoch 48/50, Loss: 0.008050892502069473\n",
      "Epoch 49/50, Loss: 0.014846284873783588\n",
      "Epoch 50/50, Loss: 0.010626697912812233\n",
      "Epoch 1/50, Loss: 0.06849604099988937\n",
      "Epoch 2/50, Loss: 0.017032675445079803\n",
      "Epoch 3/50, Loss: 0.024371681734919548\n",
      "Epoch 4/50, Loss: 0.014390560798346996\n",
      "Epoch 5/50, Loss: 0.011104459874331951\n",
      "Epoch 6/50, Loss: 0.011800965294241905\n",
      "Epoch 7/50, Loss: 0.013305947184562683\n",
      "Epoch 8/50, Loss: 0.005391746759414673\n",
      "Epoch 9/50, Loss: 0.013987712562084198\n",
      "Epoch 10/50, Loss: 0.011169414035975933\n",
      "Epoch 11/50, Loss: 0.010718594305217266\n",
      "Epoch 12/50, Loss: 0.00746192317456007\n",
      "Epoch 13/50, Loss: 0.012064558453857899\n",
      "Epoch 14/50, Loss: 0.012157176621258259\n",
      "Epoch 15/50, Loss: 0.01408347673714161\n",
      "Epoch 16/50, Loss: 0.009376715868711472\n",
      "Epoch 17/50, Loss: 0.009710859507322311\n",
      "Epoch 18/50, Loss: 0.012181645259261131\n",
      "Epoch 19/50, Loss: 0.014684369787573814\n",
      "Epoch 20/50, Loss: 0.01058882661163807\n",
      "Epoch 21/50, Loss: 0.010038202628493309\n",
      "Epoch 22/50, Loss: 0.013740713708102703\n",
      "Epoch 23/50, Loss: 0.0063358633778989315\n",
      "Epoch 24/50, Loss: 0.007699862122535706\n",
      "Epoch 25/50, Loss: 0.00916291493922472\n",
      "Epoch 26/50, Loss: 0.0053193653002381325\n",
      "Epoch 27/50, Loss: 0.015412824228405952\n",
      "Epoch 28/50, Loss: 0.012883136048913002\n",
      "Epoch 29/50, Loss: 0.007020235061645508\n",
      "Epoch 30/50, Loss: 0.009375980123877525\n",
      "Epoch 31/50, Loss: 0.005717324558645487\n",
      "Epoch 32/50, Loss: 0.007771494332700968\n",
      "Epoch 33/50, Loss: 0.009914561174809933\n",
      "Epoch 34/50, Loss: 0.006188304163515568\n",
      "Epoch 35/50, Loss: 0.014612725004553795\n",
      "Epoch 36/50, Loss: 0.007892480120062828\n",
      "Epoch 37/50, Loss: 0.008053903467953205\n",
      "Epoch 38/50, Loss: 0.013193333521485329\n",
      "Epoch 39/50, Loss: 0.013760258443653584\n",
      "Epoch 40/50, Loss: 0.013133672066032887\n",
      "Epoch 41/50, Loss: 0.010386555455625057\n",
      "Epoch 42/50, Loss: 0.013195971958339214\n",
      "Epoch 43/50, Loss: 0.015153849497437477\n",
      "Epoch 44/50, Loss: 0.010224905796349049\n",
      "Epoch 45/50, Loss: 0.007960780523717403\n",
      "Epoch 46/50, Loss: 0.0081926379352808\n",
      "Epoch 47/50, Loss: 0.012234881520271301\n",
      "Epoch 48/50, Loss: 0.01866357959806919\n",
      "Epoch 49/50, Loss: 0.009298769757151604\n",
      "Epoch 50/50, Loss: 0.012871278449892998\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class GRU_LSTM_DQN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRU_LSTM_DQN, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out, _ = self.lstm(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class GRU_DQN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRU_DQN, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class LSTM_DQN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM_DQN, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_tensor = torch.tensor(train_data.values, dtype=torch.float32)\n",
    "test_tensor = torch.tensor(test_data.values, dtype=torch.float32)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(TensorDataset(train_tensor, train_tensor), batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(test_tensor, test_tensor), batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize models, loss function, and optimizer\n",
    "input_size = train_data.shape[1]\n",
    "hidden_size = 50\n",
    "output_size = 1\n",
    "\n",
    "gru_lstm_dqn = GRU_LSTM_DQN(input_size, hidden_size, output_size)\n",
    "gru_dqn = GRU_DQN(input_size, hidden_size, output_size)\n",
    "lstm_dqn = LSTM_DQN(input_size, hidden_size, output_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "gru_lstm_optimizer = optim.Adam(gru_lstm_dqn.parameters(), lr=0.001)\n",
    "gru_optimizer = optim.Adam(gru_dqn.parameters(), lr=0.001)\n",
    "lstm_optimizer = optim.Adam(lstm_dqn.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, optimizer, train_loader, num_epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.unsqueeze(1))\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# Train the models\n",
    "train_model(gru_lstm_dqn, gru_lstm_optimizer, train_loader)\n",
    "train_model(gru_dqn, gru_optimizer, train_loader)\n",
    "train_model(lstm_dqn, lstm_optimizer, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU-LSTM-DQN Metrics: (35.37224389473442, nan, 84.87436079978943)\n",
      "GRU-DQN Metrics: (35.064564183752545, nan, 84.70393967628479)\n",
      "LSTM-DQN Metrics: (35.7964682626438, nan, 85.11770582199097)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: RuntimeWarning: overflow encountered in accumulate\n",
      "  return bound(*args, **kwds)\n",
      "C:\\Users\\Rajae\\AppData\\Local\\Temp\\ipykernel_18036\\738709997.py:19: RuntimeWarning: invalid value encountered in subtract\n",
      "  drawdown = cumulative_returns - np.maximum.accumulate(cumulative_returns)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate performance metrics\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    returns = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            outputs = model(inputs.unsqueeze(1))\n",
    "            returns.append(outputs.squeeze().numpy())\n",
    "\n",
    "    returns = np.concatenate(returns)\n",
    "\n",
    "    # Calculate Sharpe Ratio\n",
    "    sharpe_ratio = np.mean(returns) / np.std(returns) * np.sqrt(252)\n",
    "\n",
    "    # Calculate maximum drawdown\n",
    "    cumulative_returns = np.cumprod(1 + returns) - 1\n",
    "    drawdown = cumulative_returns - np.maximum.accumulate(cumulative_returns)\n",
    "    max_drawdown = np.min(drawdown)\n",
    "\n",
    "    # Calculate annual returns\n",
    "    annual_returns = np.mean(returns) * 252\n",
    "\n",
    "    return sharpe_ratio, max_drawdown, annual_returns\n",
    "\n",
    "# Evaluate the models\n",
    "gru_lstm_metrics = evaluate_model(gru_lstm_dqn, test_loader)\n",
    "gru_metrics = evaluate_model(gru_dqn, test_loader)\n",
    "lstm_metrics = evaluate_model(lstm_dqn, test_loader)\n",
    "\n",
    "print('GRU-LSTM-DQN Metrics:', gru_lstm_metrics)\n",
    "print('GRU-DQN Metrics:', gru_metrics)\n",
    "print('LSTM-DQN Metrics:', lstm_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define a function for making predictions\n",
    "def predict(model, data):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Convert input data to torch tensor\n",
    "        input_tensor = torch.tensor(data.values, dtype=torch.float32)\n",
    "        \n",
    "        # Ensure input tensor is 2D or 3D\n",
    "        if input_tensor.dim() == 1:\n",
    "            input_tensor = input_tensor.unsqueeze(0)  # Add batch dimension if input is 1D\n",
    "        elif input_tensor.dim() == 2:\n",
    "            input_tensor = input_tensor.unsqueeze(1)  # Add sequence length dimension if input is 2D\n",
    "        \n",
    "        # Forward pass to get predictions\n",
    "        predictions = model(input_tensor)\n",
    "        \n",
    "        # Convert predictions to numpy array\n",
    "        predictions = predictions.squeeze().numpy()\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Data for Prediction:\n",
      "            EURUSD  USDJPY\n",
      "2023-01-01    1.15   110.0\n",
      "2023-01-02    1.16   109.8\n",
      "2023-01-03    1.17   110.2\n",
      "2023-01-04    1.18   110.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example of creating new data for prediction\n",
    "new_data = {\n",
    "    'EURUSD': [1.15, 1.16, 1.17, 1.18],  # Example EUR/USD closing prices\n",
    "    'USDJPY': [110.0, 109.8, 110.2, 110.5]  # Example USD/JPY closing prices\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "new_data_df = pd.DataFrame(new_data, index=pd.date_range('2023-01-01', periods=4, freq='D'))\n",
    "\n",
    "print(\"New Data for Prediction:\")\n",
    "print(new_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU-LSTM Predictions: [2.6517427 2.6519353 2.6519318 2.6519606]\n",
      "GRU Predictions: [4.981039  4.9815116 4.982565  4.9835186]\n",
      "LSTM Predictions: [4.7613926 4.7613535 4.7616415 4.7618723]\n"
     ]
    }
   ],
   "source": [
    "# Example usage of predict function with new data\n",
    "predictions_gru_lstm = predict(gru_lstm_dqn, new_data_df)\n",
    "predictions_gru = predict(gru_dqn, new_data_df)\n",
    "predictions_lstm = predict(lstm_dqn, new_data_df)\n",
    "\n",
    "# Example of printing predictions\n",
    "print(\"GRU-LSTM Predictions:\", predictions_gru_lstm)\n",
    "print(\"GRU Predictions:\", predictions_gru)\n",
    "print(\"LSTM Predictions:\", predictions_lstm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
